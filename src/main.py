import logging
import akshare as ak
import pandas as pd
import numpy as np
import datetime as dt
import time
import os
from filter.analyze import analyze_stock_technical
from request_data.request_all_stocks import request_all_stocks
from request_data.request_single_stock import load_stock_data,get_latest_trade_dates
from local_process_functions.process_csv_files import process_csv_files
# from local_process.local_process import process_csv_files
import filter.slope_shadow_cal as sf
import sys
pd.set_option('display.float_format', lambda x: '%.2f' % x)

# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ æ—¥å¿—é…ç½®
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    # ç¡®ä¿logsç›®å½•å­˜åœ¨
    log_dir = 'logs'
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶å
    log_filename = f"logs\\stock_analysis_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),  # æ–‡ä»¶è¾“å‡º
            logging.StreamHandler(sys.stdout)  # æ§åˆ¶å°è¾“å‡º
        ]
    )
    
    return log_filename

# æ›¿æ¢æ‰€æœ‰ print() ä¸º logging.info()
def main():
    log_file = setup_logging()
    logger = logging.getLogger()
    
    logger.info(f"ğŸ“ æ—¥å¿—å°†ä¿å­˜åˆ°: {log_file}")


    today_market_filename = f'data\\stock_pool_data\\stock_data_pool{dt.datetime.now().strftime("%Y%m%d")}.csv'

    # æ£€æŸ¥å½“å¤©çš„è‚¡ç¥¨æ± CSVæ–‡ä»¶æ•°æ®æ˜¯å¦å­˜åœ¨
    if os.path.exists(today_market_filename):
        logger.info(f"ğŸ“ å‘ç°å·²å­˜åœ¨çš„æ•°æ®æ–‡ä»¶: {today_market_filename}")
        logger.info("ğŸ”„ ç›´æ¥åŠ è½½æœ¬åœ°CSVæ–‡ä»¶")
        stock_data_pool = pd.read_csv(today_market_filename,encoding='utf-8-sig',dtype={'ä»£ç ': str})
    else:
        logger.info(f"âŒ æœªæ‰¾åˆ°å½“å¤©æ•°æ®æ–‡ä»¶: {today_market_filename}")
        logger.info("ğŸŒ æ­£åœ¨ä»ç½‘ç»œè·å–è‚¡ç¥¨æ± æ•°æ®...")
        # è·å–è‚¡ç¥¨æ± æ•°æ®
        stock_data_pool = request_all_stocks()  # æ³¨æ„è¿™é‡Œåº”è¯¥æ˜¯å‡½æ•°è°ƒç”¨ï¼Œä¸æ˜¯to_csv
        # ä¿å­˜ä¸ºCSVæ–‡ä»¶
        stock_data_pool.to_csv(today_market_filename, index=False, encoding='utf-8-sig')
        logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {today_market_filename}")
    
    
    # ç¬¬ä¸€æ¬¡æ ‡çš„ç­›é€‰ 
    first_filtered_data = stock_data_pool[(stock_data_pool['æ¶¨è·Œå¹…'] > 3) &
                                        (stock_data_pool['æ¶¨è·Œå¹…'] < 5) & 
                                        (stock_data_pool['æ¢æ‰‹ç‡'] > 4) & 
                                        (stock_data_pool['æ¢æ‰‹ç‡'] < 10) & 
                                        (stock_data_pool['é‡æ¯”'] > 1) &
                                        (stock_data_pool['æ€»å¸‚å€¼'] > 50) & 
                                        (stock_data_pool['æ€»å¸‚å€¼'] < 100)]

    # file_path = f'e:\\desktop\\stock.csv'
    # data.to_csv(f'e:\\desktop\\stock.csv', index=False,encoding ='utf-8-sig')
    # logger.info(len(first_filtered_data))

    # ç¬¬äºŒæ¬¡æ ‡çš„ç­›é€‰
    first_filtered_data_codes = first_filtered_data['ä»£ç '].tolist()
    today = dt.datetime.now().strftime('%Y%m%d')
    start_date = (dt.datetime.now() - dt.timedelta(days=60)).strftime('%Y%m%d')  # å¢åŠ åˆ°60å¤©è·å–æ›´å¤šæ•°æ®
    
    latest_trade_date, _ = get_latest_trade_dates()
    
    if latest_trade_date is not None:
        latest_trade_date_str = latest_trade_date.strftime('%Y%m%d')
        logger.info(f"æœ€æ–°äº¤æ˜“æ—¥: {latest_trade_date.strftime('%Y-%m-%d')}")
    else:
        latest_trade_date_str = today
        logger.info(f"æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ: {today}")

    logger.info(f"å‡†å¤‡åˆ†æåˆæ¬¡ç­›é€‰å‡ºçš„{len(first_filtered_data_codes)} åªè‚¡ç¥¨")
    logger.info(f"è‚¡ç¥¨ä»£ç : {first_filtered_data_codes}")
    logger.info(f"æ•°æ®æ—¥æœŸèŒƒå›´: {start_date} åˆ° {today}")
    logger.info("="*60)

    # å­˜å‚¨åˆ†æç»“æœ
    analysis_results = []

    for i, ffdc in enumerate(first_filtered_data_codes):
        logger.info(f"\n({i+1}/{len(first_filtered_data_codes)}) æ­£åœ¨åˆ†æè‚¡ç¥¨: {ffdc}")
        
        try:
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            file_path = f'data\\single_stock_data\\{ffdc}_{latest_trade_date_str}.csv'
            
            # ä½¿ç”¨å‡½æ•°è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜å…ˆæœ¬åœ°ï¼Œå¦åˆ™ç½‘ç»œè·å–ï¼‰
            ffdc_stock_data, from_local = load_stock_data(ffdc, file_path, start_date, today)
            
            if ffdc_stock_data is not None and not ffdc_stock_data.empty:
                logger.info(f"  ğŸ“Š æ•°æ®é‡: {len(ffdc_stock_data)} å¤©")
                
                # è¿›è¡ŒæŠ€æœ¯åˆ†æ
                analysis = analyze_stock_technical(ffdc_stock_data, ffdc)
                analysis_results.append(analysis)
                
                # æ˜¾ç¤ºåˆ†æç»“æœ
                logger.info(f"  ğŸ“ˆ æŠ€æœ¯åˆ†æç»“æœ:")
                logger.info(f"    æœ€æ–°ä»·æ ¼: {analysis['latest_price']:.2f}")
                logger.info(f"    æœ€æ–°æ—¥æœŸ: {analysis['latest_date']}")
                logger.info(f"    ä¸‹è·Œè¶‹åŠ¿: {'æ˜¯' if analysis['is_downtrend'] else 'å¦'}")
                logger.info(f"    é«˜ä½ä¸Šå½±çº¿: {'æœ‰' if analysis['has_high_shadow'] else 'æ— '}")
                logger.info(f"    MA5: {analysis['ma5']:.2f}" if analysis['ma5'] else "    MA5: æ•°æ®ä¸è¶³")
                logger.info(f"    MA20: {analysis['ma20']:.2f}" if analysis['ma20'] else "    MA20: æ•°æ®ä¸è¶³")
                
                if analysis['pass_filter']:
                    logger.info(f"  âœ… {ffdc} é€šè¿‡æŠ€æœ¯åˆ†æç­›é€‰!")
                else:
                    reasons = []
                    if analysis['is_downtrend']:
                        reasons.append("ä¸‹è·Œè¶‹åŠ¿")
                    if analysis['has_high_shadow']:
                        reasons.append("é«˜ä½ä¸Šå½±çº¿")
                    logger.info(f"  âŒ {ffdc} æœªé€šè¿‡ç­›é€‰ï¼ŒåŸå› : {', '.join(reasons)}")
            else:
                logger.info(f"  âŒ æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®")
                analysis_results.append({
                    'code': ffdc,
                    'valid_data': False,
                    'reason': 'æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®'
                })
                
        except Exception as e:
            logger.info(f"  âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            analysis_results.append({
                'code': ffdc,
                'valid_data': False,
                'reason': f'é”™è¯¯: {e}'
            })
        
        # åªæœ‰ä»ç½‘ç»œè·å–æ•°æ®æ—¶æ‰éœ€è¦ç­‰å¾…
        if not from_local:
            time.sleep(1)

    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "="*60)
    logger.info("æŠ€æœ¯åˆ†ææ±‡æ€»ç»“æœ:")
    logger.info("="*60)

    passed_stocks = []
    for result in analysis_results:
        if result.get('valid_data', False):
            if result.get('pass_filter', True):
                passed_stocks.append(result)
                logger.info(f"âœ… {result['code']} - é€šè¿‡ç­›é€‰")
            else:
                reasons = []
                if result.get('is_downtrend'):
                    reasons.append("ä¸‹è·Œè¶‹åŠ¿")
                if result.get('has_high_shadow'):
                    reasons.append("é«˜ä½ä¸Šå½±çº¿")
                logger.info(f"âŒ {result['code']} - æœªé€šè¿‡: {', '.join(reasons)}")
        else:
            logger.info(f"âš ï¸  {result['code']} - {result.get('reason', 'æœªçŸ¥é”™è¯¯')}")

    logger.info(f"\næœ€ç»ˆç»“æœ: {len(passed_stocks)} åªè‚¡ç¥¨é€šè¿‡æŠ€æœ¯åˆ†æç­›é€‰")

    if passed_stocks:
        logger.info("\nç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨è¯¦æƒ…:")
        for stock in passed_stocks:
            logger.info(f"ä»£ç : {stock['code']}")
            logger.info(f"  æœ€æ–°ä»·æ ¼: {stock['latest_price']:.2f}")
            logger.info(f"  MA5: {stock['ma5']:.2f}" if stock['ma5'] else "  MA5: æ•°æ®ä¸è¶³")
            logger.info(f"  MA20: {stock['ma20']:.2f}" if stock['ma20'] else "  MA20: æ•°æ®ä¸è¶³")
            logger.info(f"  æ•°æ®å¤©æ•°: {stock['data_days']}")


# if __name__ == "__main__":
#     # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
#     if len(sys.argv) > 1 and sys.argv[1] == 'csv':
#         print("ğŸ”„ å¤„ç†CSVæ–‡ä»¶æ¨¡å¼")
#         process_csv_files()
#     else:
#         print("ğŸ”„ åœ¨çº¿è·å–æ•°æ®æ¨¡å¼")
#         main()  # è°ƒç”¨ä¸»ç¨‹åº
if __name__ == "__main__":
    main()  # è°ƒç”¨ä¸»ç¨‹åº